| Initial Papers |
|------|
|[Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)|
|[Quantum Computing since Democritus](https://scottaaronson.blog/?p=762)|
|[The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)|
|[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)|
|[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.2329.pdf)|
|[Keeping the neural networks simple by minimizing the description length of the weights](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf)|
|[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1506.03134.pdf)|
|[ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)|
|[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06391.pdf)|
|[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1811.06965.pdf)|
|[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)|
|[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/pdf/1511.07122.pdf)|
|[Mask R-CNN](https://arxiv.org/pdf/1704.01212.pdf)|
|[Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)|
|[Generative Adversarial Nets](https://arxiv.org/pdf/1409.0473.pdf)|
|[Wide Residual Networks](https://arxiv.org/pdf/1603.05027.pdf)|
|[Dual Path Networks](https://arxiv.org/pdf/1706.01427.pdf)|
|[End-to-End Deep Learning for Computer Vision](https://arxiv.org/pdf/1611.02731.pdf)|
|[GPT-2: Language Models are Unsupervised Multitask Learners](https://arxiv.org/pdf/1806.01822.pdf)|
|[Zero-shot Learning with Semantic Output Codes](https://arxiv.org/pdf/1405.6903.pdf)|
|[Adam: A Method for Stochastic Optimization](https://arxiv.org/pdf/1410.5401.pdf)|
|[Deep Learning for Computer Vision with Python (Introduction)](https://arxiv.org/pdf/1512.02595.pdf)|
|[Differentiable Softmax-Based Attention for Transformer Models](https://arxiv.org/pdf/2001.08361.pdf)|
|[The Symmetry of Gödel’s Theorems](https://arxiv.org/pdf/math/0406077.pdf)|
|[Machine Super Intelligence](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf)|
|[Theory of Algorithm](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf)|
|[CS231n: Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)|

